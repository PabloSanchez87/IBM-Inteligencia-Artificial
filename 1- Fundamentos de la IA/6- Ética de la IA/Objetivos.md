# Ética de la IA

La Inteligencia artificial (IA) está en todas partes. La vemos en anuncios, chatbots, motores de recomendación de vídeos y de música, asistentes inteligentes (como Siri o Bixby), gestión de atención sanitaria y coches inteligentes. Pero, ¿confía en la IA? Elon Musk ha declarado que cree que la IA es más peligrosa que las armas nucleares. 

¿Significa esto que tiene miedo de una invasión de robots de IA? Probablemente no. Es probable que esté más preocupado por cómo la IA podría influir en nuestras vidas de maneras que tal vez ni nos demos cuenta. Por eso es importante que la IA sea fiable. Ese es el campo en el que trabaja la ética de IA.

La ética de IA es un campo multidisciplinal que estudia cómo optimizar la repercusión positiva de la IA y reducir los resultados no deseados o adversos. La confianza en la IA se basa en cinco pilares éticos:

- Imparcialidad
- Solidez
- Explicabilidad
- Transparencia
- Privacidad

## Objetivos

- Identificar los cinco pilares de la ética de la IA
- Describir la imparcialidad en IA
- Describir los atributos protegidos
- Identificar grupos privilegiados y grupos no privilegiados
- Explicar el sesgo de la IA
- Identificar la solidez
- Describir la solidez frente a adversarios en la IA
- Explicar cómo un adversario puede influir en un sistema de IA
- Identificar ataques de adversario
- Describir la explicabilidad
- Comparar interpretabilidad y explicabilidad
- Deﬁnir la transparencia
- Describir el gobierno
- Identificar las funciones empresariales y los aspectos de la transparencia en los que intervienen
- Identificar información personal
- Identificar información personal confidencial
- Reconocer la anonimización de modelos
- Describir la privacidad diferencial
- Explicar la minimización de datos